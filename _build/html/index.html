

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Welcome to Data Visualization! &#8212; Data Visualization by Kent D. Lee (and others)</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="#">Data Visualization by Kent D. Lee (and others)</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Welcome to Data Visualization!</a><ul>
<li><a class="reference internal" href="#python-programming">Python Programming</a></li>
<li><a class="reference internal" href="#computer-architecture-and-performance">Computer Architecture and Performance</a><ul>
<li><a class="reference internal" href="#the-moral-of-the-story">The Moral of the Story</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-science">Data Science</a></li>
<li><a class="reference internal" href="#the-data-science-life-cycle">The Data Science Life Cycle</a></li>
<li><a class="reference internal" href="#visualization-workflow">Visualization Workflow</a></li>
<li><a class="reference internal" href="#data-acquisition">Data Acquisition</a></li>
<li><a class="reference internal" href="#the-dataframe">The DataFrame</a></li>
<li><a class="reference internal" href="#munging-data-with-python">Munging Data with Python</a></li>
<li><a class="reference internal" href="#id1">Data Acquisition</a><ul>
<li><a class="reference internal" href="#building-a-dataset-with-a-webcrawler">Building a Dataset with a Webcrawler</a></li>
<li><a class="reference internal" href="#reading-a-json-file-to-build-a-dataframe">Reading a JSON file to build a Dataframe</a></li>
<li><a class="reference internal" href="#exercise-2">Exercise 2</a></li>
<li><a class="reference internal" href="#exercise-3">Exercise 3</a></li>
<li><a class="reference internal" href="#exercise-4">Exercise 4</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-graph-types">Common Graph Types</a><ul>
<li><a class="reference internal" href="#stacked-area-plots">Stacked Area Plots</a></li>
<li><a class="reference internal" href="#box-and-whisker-plots">Box and Whisker Plots</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/index.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="welcome-to-data-visualization">
<h1>Welcome to Data Visualization!<a class="headerlink" href="#welcome-to-data-visualization" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p>Welcome to Data Visualization. In this course you learn how to manipulate and visualize data to learn from it.
You learn from data when you are able to classify new instances or make predictions based on previous
experience. We’ll be studying many example of data visualization and we’ll look at getting data into the right format to
be analyzed.</p>
<p>An excellent textbook is “Data Visualisation: A Handbook for Data Driven Design” by Andy Kirk. The text
covers many of the principles and ideas necessary for good data analysis and visualization. This website
will outline some of his principles. More details can be found in his text.</p>
<div class="section" id="python-programming">
<h2>Python Programming<a class="headerlink" href="#python-programming" title="Permalink to this headline">¶</a></h2>
<p>We’ll start with some Python programming. Please take a look at these videos on Python programming. Watch them up through the video on reading XML files
in chapter 4. You can also consult the following websites for additional background on programming with
Python.</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://www.youtube.com/playlist?list=PL1DE477438120C9EF">Lectures on Python Programming</a></li>
<li><a class="reference external" href="http://cs.luther.edu/~leekent/IntroToComputing">Support Site for the Lectures on Python Programming</a></li>
<li><a class="reference external" href="http://cs.luther.edu/~leekent/CS2Plus">Additional Examples of Python Programming</a></li>
<li><a class="reference external" href="https://kentdlee.github.io/SCSI/build/html/index.html">An online text on Python Programming</a></li>
<li><a class="reference external" href="http://interactivepython.org/runestone/static/thinkcspy/index.html">You might also find this online text to be useful</a></li>
</ul>
</div></blockquote>
<p>If you want an additional textbook or textbooks on Python programming you can check out my two texts. The
first of these goes with the video lectures found above.</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://www.amazon.com/Programming-Fundamentals-Undergraduate-Computer-Science/dp/1447166418">Python Programming Fundamentals</a></li>
<li><a class="reference external" href="https://www.amazon.com/Structures-Algorithms-Undergraduate-Computer-Science/dp/3319130714/ref=pd_sim_14_1?_encoding=UTF8&amp;pd_rd_i=3319130714&amp;pd_rd_r=43ee148a-aff3-11e8-ab28-01ad97aa66bb&amp;pd_rd_w=gfZsy&amp;pd_rd_wg=NhjP4&amp;pf_rd_i=desktop-dp-sims&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_p=18bb0b78-4200-49b9-ac91-f141d61a1780&amp;pf_rd_r=6PP30YNX074T4S2FNGCP&amp;pf_rd_s=desktop-dp-sims&amp;pf_rd_t=40701&amp;psc=1&amp;refRID=6PP30YNX074T4S2FNGCP">Data Structures and Algorithms with Python</a></li>
</ul>
</div></blockquote>
<p>You want to get good at string manipulation, reading and writing XML files, and working with lists and dictionaries. Reading
JSON data, Beautiful Soup, and sending HTML requests with Python will be valuable skills to learn during
data collection. You need to also be good at reading and writing files.</p>
</div>
<div class="section" id="computer-architecture-and-performance">
<h2>Computer Architecture and Performance<a class="headerlink" href="#computer-architecture-and-performance" title="Permalink to this headline">¶</a></h2>
<p>There are a few things you need to learn about computer architecture given that we will often be
dealing with large amounts of data. When we are ready to work with a large amount of data we need to be
cognizant of a few things about computers. CPUs are fastest. Memory is slower then a CPU but faster than a
disk drive. Disk drives and accessing data over the internet are much slower than memory as depicted here.</p>
<div class="figure">
<img alt="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter1/1_4_StorageDeviceHierarchy.jpg" src="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter1/1_4_StorageDeviceHierarchy.jpg" />
</div>
<p>Caching can make some programs appear to run faster. A cache is a smaller (i.e. faster, more expensive)
memory that can be used to hold data that the computer thinks has a reasonable chance of being used soon.</p>
<div class="figure">
<img alt="https://qph.fs.quoracdn.net/main-qimg-64d592b11dc2b5c990fc6e10e9396b93.webp" src="https://qph.fs.quoracdn.net/main-qimg-64d592b11dc2b5c990fc6e10e9396b93.webp" />
</div>
<p>Here are some sources of information about Computer Architecture and how it affects the performance of
dealing with big data.</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://queue.acm.org/detail.cfm?id=1563874">Dealing with Big Data and Databases</a> this text is an
excellent description of some of the challenges of working with big data, especially when it resides
in a database.</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore’s Law</a> deals with the doubling of memory capacity
as the number of transistors doubles around every two years. This means that we can expect to see
continued growth in the size of data that can be stored on hard drives and in the memory of a computer.</li>
<li>While SSD’s are fast, DRAM (the memory of a computer) is typically about 5-10 times faster. An SSD
might read data at 100-150 MB/second or faster. A 500GB Samsung SSD has a sequential read speed of
550 MB/second. This is much slower than DRAM which can be read at somewhere around 1927 MB/second
and if the data is cached, then data could be read as fast as 3748 MB/second. <a class="reference external" href="https://superuser.com/questions/1173675/how-much-faster-is-memory-ram-compared-to-ssd-for-random-access/1173713">See this site for a
discussion of this</a>.</li>
</ul>
</div></blockquote>
<p>There are a few other factors in how our programs will run when dealing with big data. One factor is called
<em>Computational Complexity</em> and it is the study of how efficiently our programs are written. Nothing, not
even the fastest CPU, can overcome a poorly written program. We must write our programs efficiently and in
terms of computational complexity that means to be aware of any loops you write in a program.</p>
<p>We must also be concerned about issues like how many times you access a file on disk, how
much of the main memory (RAM or DRAM) you are using in your program, and how often you move data back and
forth from the disk into memory. Sometimes you may not even be aware that you are moving data from DRAM
to disk because of something called virtual memory that uses the disk to hold the contents of DRAM when
you don’t have enough DRAM to contain all the data in your program at one time.</p>
<p>Another big issue that affects the performance of our programs is what language the program is implemented
with. We will write Python code, but whenever possible we should rely on library code to do something for
us rather than writing Python code to do it ourselves. Libraries are often implemented in C and run much
faster than Python code.</p>
<p>All of these considerations factor into the performance of our programs. And often times it is a job
that is best left to experts in the field, but sometimes writing our own code is unavoidable. Much of
the recent work in Data Science has been toward optimizing algorithms that deal with large amounts of
data to get the absolute best performance possible.</p>
<div class="section" id="the-moral-of-the-story">
<h3>The Moral of the Story<a class="headerlink" href="#the-moral-of-the-story" title="Permalink to this headline">¶</a></h3>
<p>Whenever possible, we are going to want to rely on a library or module to do a computation for us. As a
last resort we should rely on writing significant Python code ourselves. Modules that we use are
sometimes written in C, not Python. In addition, modules have often been optimized to work with disk
and memory by caching information and/or reading from disk only when absolutely necessary. And, modules
will often be written to read from disk only once rather than read data inefficiently.</p>
<p>Thankfully, there are many modules
that have now been written to be as efficient as possible when dealing with large amounts of data. We
will be learning about several of these modules or libraries this semester.</p>
</div>
</div>
<div class="section" id="data-science">
<h2>Data Science<a class="headerlink" href="#data-science" title="Permalink to this headline">¶</a></h2>
<p>What is Data Science?</p>
<div class="figure">
<img alt="https://cdn-images-1.medium.com/max/1000/1*mgXvzNcwfpnBawI6XTkVRg.png" src="https://cdn-images-1.medium.com/max/1000/1*mgXvzNcwfpnBawI6XTkVRg.png" />
</div>
<p>Data Science starts with data. Good resources for data can be found at these sites.</p>
<ul class="simple">
<li><a class="reference external" href="http://bigdata-madesimple.com/70-amazing-and-free-data-sources-for-data-visualization/">http://bigdata-madesimple.com/70-amazing-and-free-data-sources-for-data-visualization/</a></li>
<li><a class="reference external" href="http://kaggle.com">http://kaggle.com</a></li>
<li><a class="reference external" href="http://toolbox.google.com/datasetsearch">Google Dataset Search</a></li>
</ul>
</div>
<div class="section" id="the-data-science-life-cycle">
<h2>The Data Science Life Cycle<a class="headerlink" href="#the-data-science-life-cycle" title="Permalink to this headline">¶</a></h2>
<p>Applying Data Science begins with a question. That is the most important part of data science, asking questions.
For many businesses the question probably revolves around revenue. Questions might be:</p>
<ul class="simple">
<li>Is there a more efficient way of doing this?</li>
<li>What’s the next big thing that we should be focusing on?</li>
<li>Did we do a good job?</li>
<li>How can we improve our product?</li>
<li>How can we do it faster?</li>
</ul>
<p>Questions like these are hard to answer and to answer them requires data to back up any claims that are
made. Asking a good question is difficult. Gathering the data to answer the question is at least ten
times harder. Most of the work in Data Science is in data acquisition.</p>
<p><a class="reference external" href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle">Microsoft has a good website detailing the lifecycle of a Data Science project</a>. You should
take a look at this to understand the life cycle and in particular the data acquisition process described
on that page.</p>
</div>
<div class="section" id="visualization-workflow">
<h2>Visualization Workflow<a class="headerlink" href="#visualization-workflow" title="Permalink to this headline">¶</a></h2>
<p>It is important to develop a visualization workflow. This workflow should be repeated (and improved on) with
each project. The process of developing a visualization is that of developing a compelling story/narrative
around the data. To be effective in generating this narrative, you need to observe the following.</p>
<blockquote>
<div><ul class="simple">
<li>Be pragmatic.</li>
<li>Reduce the randomness of your approach.</li>
<li>Protect experimentation.</li>
<li>Facilitate adaptability and iteration.</li>
<li>Develop a repeatable process.</li>
</ul>
</div></blockquote>
<p>To be successful using these principles, you need to take notes and use pen and paper to sketch out what
you intend to do. Note taking is important because creative thoughts come at odd times and need to be
written down to be available to you when you have time to build upon them. Manage your time and resources
well, but leave time for creative thinking. Sometimes pressures may cause you to develop some rules-of-thumb
for finding answers to some questions.</p>
<p>Be sure to communicate with your audience and stakeholders. Do your research. Pay attention to detail. Be
honest with yourself. And above all else, <strong>learn</strong>. We all need to work at <strong>learning</strong> as this
is a rapidly expanding field and you need to stay current.</p>
<p>So, here are some steps to take in developing this workflow.</p>
<ol class="arabic simple">
<li>Formulate a brief - According to Andy Kirk, a brief represents a set of expectations and captures all the relevant information about a task or project.</li>
<li>Start from curiosity. It might be your curiosity. It might be the curiosity of the stakeholder, your audience, or other potential intrigue of yet unidentified individuals.</li>
<li>Identify your audience. The idea of intrigue should be not only your intrigue. Your job is to create intrigue in your audience. This draws people in to the narrative and gives them a goal in understand your data visualization. Often presenting a question that is answered (at least in part) in the data can help create that intrigue.</li>
<li>Understand your contraints. Time constraints, tool constraints, All your constraints will factor into what you end up doing.</li>
<li>Understand how the work will be consumed. You especially want to know the frequency with which this visualization will need to be repeated. If it needs to be repeated frequently, the it should be as automated a process as possible. More attention to the process may be necessary if it will be frequently reproduced.</li>
</ol>
</div>
<div class="section" id="data-acquisition">
<h2>Data Acquisition<a class="headerlink" href="#data-acquisition" title="Permalink to this headline">¶</a></h2>
<p>Building a pipeline for data acquisition means writing code that can be used to acquire, munge, and
refresh the data as often as is necessary given the needs of the project. Automation of data acquisition
for a project is our goal. We want to write code to allow us to push a button to refresh large data
sets coming from multiple sources.</p>
<p>Munging data refers to writing a program (Python is an excellent choice for this) that massages the data
into a format that we can use in our data pipeline. The Pandas <em>Dataframe</em> has become very important
in managing data for a project. We’ll first learn what a <em>Dataframe</em> is and how to build one.</p>
</div>
<div class="section" id="the-dataframe">
<h2>The DataFrame<a class="headerlink" href="#the-dataframe" title="Permalink to this headline">¶</a></h2>
<p>We start by learning to use notebooks and build dataframes in Pandas. <a class="reference internal" href="notebooks/TheDataframe.html"><span class="doc">Take a look at this
example of creating a dataframe</span></a>.</p>
</div>
<div class="section" id="munging-data-with-python">
<h2>Munging Data with Python<a class="headerlink" href="#munging-data-with-python" title="Permalink to this headline">¶</a></h2>
<p>Munging is sometimes called <em>Data Wrangling</em> or <em>Massaging the Data</em>. All terms mean the same thing. When we
get data from a source it is not always in the proper format for using all the tools that we want to use.</p>
<p>Consider the Avocado data set which can be found on Kaggle here.</p>
<p><a class="reference external" href="https://www.kaggle.com/neuromusic/avocado-prices#avocado.csv">https://www.kaggle.com/neuromusic/avocado-prices#avocado.csv</a></p>
<p>You can download this data set from here.</p>
<p><a class="reference external" href="http://cs.luther.edu/~leekent/avocado.csv">http://cs.luther.edu/~leekent/avocado.csv</a></p>
<p>This is a CSV (Comma Separated Values) file. It can be read by a Python program like the one below. The
file and the program need to be saved in the same folder or directory to run this program.</p>
<p>Note the use of the <em>split</em> method below with a comma as the separator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;avocado.csv&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>The file can also be read from the internet directly if you know the URL. The urllib.request module
is a Python3 module that allows you to open a file on the web. When the file is downloaded it is
in unicode format. So, <em>decode</em> must be called on anything that is read in this format.</p>
<p>Take a look at the code below. It contains some extra code for taking apart the fields in a CSV file
and then putting them back together. In between taking the CSV records apart and putting them back
together you can do any processing that you might need to do to get your data ready for some further
analysis.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">urllib.request</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="s2">&quot;http://cs.luther.edu/~leekent/avocado.csv&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
        <span class="c1"># Fix anything that needs fixing in the data.</span>
        <span class="c1"># Your code goes here for fixing/gathering data.</span>
        <span class="c1"># Then you start rebuilding the string to recreate the fixed up file.</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">+</span><span class="s2">&quot;,&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">]</span>
        <span class="c1"># Write a new file? Print will work if you redirect output.</span>
        <span class="c1"># The [:-1] on the resulting string removes the last comma.</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lst</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h2>Data Acquisition<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>We don’t always get the data that we want in a file. Sometimes the data is available on the web and we need
to build our own data table. In that case we might use the <a class="reference external" href="http://docs.python-requests.org/en/master/">Python Requests Library</a>.
This library is very
popular and is used widely for data acquisition.</p>
<p>The Requests library can be used for screen scraping. See this tutorial on <a class="reference external" href="https://docs.python-guide.org/scenarios/scrape/">Screen Scraping with the
Requests Library</a> for help on doing this. The other
common framework for screen scraping is called <a class="reference external" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a>.
You can <a class="reference external" href="https://www.dataquest.io/blog/web-scraping-tutorial-python/">work through a tutorial on BeautifulSoup by clicking here</a>.</p>
<p>Another use of the Requests Library is for accessing API’s on the web. An API is an Application
Programming Interface. A Web-based API is generally implemented as a RESTful API. RESTful interfaces
are servers on the internet that accept URL requests and respond with data in much the same way a web
server would respond to the request for an HTML page. However, the RESTful API service may respond with
a CSV or JSON file as its result.
<a class="reference external" href="https://tutorialedge.net/python/python-http-requests-tutorial/">Read this tutorial</a>
to get started using the Requests Library to read data from a RESTful source.</p>
<p>You might need to see how to <a class="reference internal" href="notebooks/ParsingHTMLandusingXPath.html"><span class="doc">access data via an xpath</span></a>.</p>
<div class="section" id="building-a-dataset-with-a-webcrawler">
<h3>Building a Dataset with a Webcrawler<a class="headerlink" href="#building-a-dataset-with-a-webcrawler" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://towardsdatascience.com/data-analytics-with-python-by-web-scraping-illustration-with-cia-world-factbook-abbdaa687a84">This tutorial takes you through an example of building a website with a Webcrawler application</a>. This can
work sometimes, but it depends on the website you are trying to access as some websites will not
want to provide information to a program. Programs written like this can <em>steal</em> another company’s data
in seconds. So, it is often the case that webcrawler applications get flagged and webserver deny access
to them. The tutorial provide here is not subject to these problems.</p>
</div>
<div class="section" id="reading-a-json-file-to-build-a-dataframe">
<h3>Reading a JSON file to build a Dataframe<a class="headerlink" href="#reading-a-json-file-to-build-a-dataframe" title="Permalink to this headline">¶</a></h3>
<p>Reading JSON data is another skill you need as a data scientist. <a class="reference external" href="https://www.dataquest.io/blog/python-json-tutorial/">This tutorial</a> provides
a good introduction to reading JSON in your data acquisition program. You should take a look at this
notebook on how to install the ijson and possibly create your own environment in which to install
it.</p>
</div>
<div class="section" id="exercise-2">
<h3>Exercise 2<a class="headerlink" href="#exercise-2" title="Permalink to this headline">¶</a></h3>
<p>Pose a question. For instance, “Do increases in Avocado consumption predict increases in home sales?”
Write some screen scraper code, using the Requests Library and/or BeautifulSoup,
to gather information to help answer your question (not this avocado/home sales question, but your own question). Place the collected
data in a CSV file with proper headings. Describe the question, the collected data, and the program
used to collect the information.</p>
</div>
<div class="section" id="exercise-3">
<h3>Exercise 3<a class="headerlink" href="#exercise-3" title="Permalink to this headline">¶</a></h3>
<p>Pose a question and query a RESTful API to gather information about the answer to that question. Use the
Requests Library to gather the information from the API and put it into a CSV file. In the Python program
write a comment at the top that indicates the question, the API being used, and the data that is being
collected to answer the posed question.</p>
</div>
<div class="section" id="exercise-4">
<h3>Exercise 4<a class="headerlink" href="#exercise-4" title="Permalink to this headline">¶</a></h3>
<p>Pose a question that you need to gather a large dataset to either prove or disprove. Then go to the
web and find data that supports or disproves your hypothesis. You may use JSON data, XML data, a
webcrawler, or any means necessary to get acquire the data that you need.</p>
</div>
</div>
<div class="section" id="common-graph-types">
<h2>Common Graph Types<a class="headerlink" href="#common-graph-types" title="Permalink to this headline">¶</a></h2>
<p>Here are some guides to building various graphs.</p>
<div class="section" id="stacked-area-plots">
<h3>Stacked Area Plots<a class="headerlink" href="#stacked-area-plots" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="notebooks/Introduction to Plotting Exercise.html"><span class="doc">In this notebook</span></a> I work with the <a class="reference external" href="_static/movies.csv">movie database</a> to build a stacked area plot and a few other example graphs. Perhaps one of the most important parts of this notebook is in creating a pivot_table which takes columns from a DataFrame and builds a new DataFrame from it where the values in a column become columns in a new DataFrame.</p>
</div>
<div class="section" id="box-and-whisker-plots">
<h3>Box and Whisker Plots<a class="headerlink" href="#box-and-whisker-plots" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="notebooks/Shared Bike Service Data.html"><span class="doc">In this notebook</span></a> you learn about Box and Whisker Plots and how they can be used to examine the same of data in a column.</p>
</div>
</div>
</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="#">Data Visualization by Kent D. Lee (and others)</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Kent D. Lee.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>